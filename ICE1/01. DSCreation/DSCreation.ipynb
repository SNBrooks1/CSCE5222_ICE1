{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrape for the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\School\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\School\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "\n",
    "# Webpage/URL Handling\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "\n",
    "# NLP Processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_tagged: takes in an element, determines if the element contains \n",
    "# a html tag, and returns the boolean determination.\n",
    "def is_tagged(element):\n",
    "    \n",
    "    # Sets html tags.\n",
    "    html_tagnames = ['head', 'meta','style', 'script', 'title', '[document]']\n",
    "    \n",
    "    # If the element is part of an html tag or is a comment, return false.\n",
    "    # Otherwise, return true.\n",
    "    if (element.parent.name in html_tagnames) or (isinstance(element, Comment)):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# html_to_text: Takes in the data read in from a html, filters out the\n",
    "# html tags, and returns the string.\n",
    "def html_to_text(body):\n",
    "    # beautiful soup object created.\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    \n",
    "    # Gets the text from soup\n",
    "    texts = soup.findAll(text=True)\n",
    "    \n",
    "    # Filters out the html tags from the text and returns the string.\n",
    "    visible_texts = filter(is_tagged, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_site: Reads in a url, performs tokenization and stopword removal, then returns the \n",
    "# string.\n",
    "def scrape_site(url):\n",
    "    \n",
    "    # Reads in the url\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    \n",
    "    # Sets the text_to_tokenize.\n",
    "    text_to_tokenize = html_to_text(html)\n",
    "    \n",
    "    # Tokenizes the text.\n",
    "    tokens = word_tokenize(html_to_text(html))\n",
    "    \n",
    "    # Removes the stopwords.\n",
    "    tokens_cleaned = [word for word in tokens if not word in stopwords.words('english')]\n",
    "    \n",
    "    # Creates a string from the tokens\n",
    "    text_clean = (\" \").join(tokens_cleaned)\n",
    "        \n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the urls and performed the scraping/stop word removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.cnn.com/2021/03/05/cars/cavnue-self-driving-lanes/index.html',\n",
    "        'https://www.pbs.org/newshour/nation/uber-launch-fleet-self-driving-volvos-will-pittsburgh-residents-hop',\n",
    "        'https://www.npr.org/2021/06/05/1003623528/california-approves-pilot-program-for-driverless-rides',\n",
    "       'https://www.brookings.edu/research/autonomous-vehicles-as-a-killer-app-for-ai/']\n",
    "url_body_text=[]\n",
    "\n",
    "# Load the url_body_text array with scraped data from the urls.\n",
    "for address in urls:\n",
    "    url_body_text.append(scrape_site(address))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and output the dataframe then set the dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>na</td>\n",
       "      <td>Markets Tech Media Success Perspectives Videos...</td>\n",
       "      <td>tech</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>Full Episode Tuesday , Sep 7 Close Menu PBS Ne...</td>\n",
       "      <td>tech</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>Accessibility links Skip main content Keyboard...</td>\n",
       "      <td>tech</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>Skip main content Search Brookings About Us Pr...</td>\n",
       "      <td>tech</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FileName                                            Content Category  \\\n",
       "0       na  Markets Tech Media Success Perspectives Videos...     tech   \n",
       "1       na  Full Episode Tuesday , Sep 7 Close Menu PBS Ne...     tech   \n",
       "2       na  Accessibility links Skip main content Keyboard...     tech   \n",
       "3       na  Skip main content Search Brookings About Us Pr...     tech   \n",
       "\n",
       "  Complete_Filename  \n",
       "0                na  \n",
       "1                na  \n",
       "2                na  \n",
       "3                na  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the data.\n",
    "data = {'FileName':['na','na','na','na'], 'Content': url_body_text, 'Category': ['tech', 'tech', 'tech','tech'], \n",
    "        'Complete_Filename': ['na','na','na','na']}\n",
    "\n",
    "# Create the dataframe from the data.\n",
    "df_AVArticles = pd.DataFrame(data=data)\n",
    "\n",
    "# Output the dataframe.\n",
    "df_AVArticles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the csv file from the dataframe.\n",
    "df_AVArticles.to_csv('AVArticles_dataset.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
